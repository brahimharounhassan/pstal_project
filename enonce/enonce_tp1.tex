\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{amsmath, amssymb}
\usepackage{geometry}
\usepackage{listings}
\usepackage{color}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}
\usepackage{enumitem}

\geometry{margin=2.5cm}
\setlength{\parindent}{0pt}
\setlength{\parskip}{1em}

\title{Étiqueteur POS avec réseaux récurrents}
\date{}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstset{style=mystyle}

\begin{document}

\maketitle

\section{Introduction}

Tous les travaux pratiques de PSTAL consistent à développer et évaluer un système de prédiction de structures linguistiques à partir du texte. Ces structures peuvent être très diverses, allant du rôle grammatical de chaque mot (par exemple : nom, verbe, adjectif) aux entités nommées contenues dans les phrases (\textit{$\text{Carlos}_{[\text{PERS}]}$} accompagne les étudiant.e.s de Centrale $\text{Marseille}_{[\text{ORG}]}$ à $\text{Luminy}_{[\text{LOC}]}$). Chaque TP se concentrera sur un seul type de structure à prédire ; pour ce premier TP, nous nous concentrons sur les \textbf{parties du discours} (POS, \textit{Part of Speech}).

\section{L’étiquetage en parties du discours}

Dans cette tâche, chaque mot reçoit une étiquette de partie du discours (POS). Ces étiquettes indiquent le rôle grammatical du mot dans la phrase, par exemple : le mot \textit{été} est un nom (étiquette \texttt{NOUN}) dans \textit{L’été arrive}.\footnote{Nous utiliserons les étiquettes Universal Dependencies (UD), décrites ici : \url{https://universaldependencies.org/u/pos/}.}

Il s’agit d’une tâche d’étiquetage de séquences : pour chaque phrase $w_1, w_2, \dots, w_n$ en entrée, il faut prédire une séquence d’étiquettes $t_1, t_2, \dots, t_n$ de même longueur :

\[
\begin{array}{ccccccc}
&w_1 & w_2 & w_3 & w_4 & w_5 & w_6 \\
x = & \text{L’} & \text{été} & \text{arrive} & \text{à} & \text{Marseille} & \text{.} \\
& \downarrow & \downarrow & \downarrow & \downarrow & \downarrow & \downarrow \\
y = & \texttt{DET} & \texttt{NOUN} & \texttt{VERB} & \texttt{ADP} & \texttt{PROPN} & \texttt{PUNCT}\\
& t_1 & t_2 & t_3 & t_4 & t_5 & t_6 \\
\end{array}
\]

Les défis de cette tâche sont :
\begin{enumerate}
    \item Certains mots sont ambigus (par exemple : \textit{été} est un verbe dans \textit{j’ai été informée}) ;
    \item Le contexte — c’est-à-dire les mots d’avant et d’après — joue un rôle crucial pour désambiguïser les mots ayant plusieurs POS possibles ;
    \item Le système doit être capable de prédire des POS pour des mots non observés dans le corpus d’entraînement, appelés \textit{OOV} (\textit{out-of-vocabulary}) (par exemple : la plupart des noms propres).
\end{enumerate}

Nous nous concentrerons sur les deux premiers défis. Le troisième (gestion des OOV) est proposé en extension.

\section{Corpus Sequoia et format CoNLL-U+}

Pour ce TP et les suivants, nous utiliserons le corpus \textbf{Sequoia}, contenant 3\,099 phrases en français annotées avec plusieurs niveaux d’informations.\footnote{Les détails se trouvent dans le fichier \texttt{sequoia/README.md} fourni, voir Sec. 4.}

Ouvrez le fichier fourni \texttt{sequoia-ud.parseme.frsemcor.simple.small} pour lire les explications ci-dessous avec le corpus sous les yeux. Les fichiers contiennent du texte encodé en UTF-8 ; vous pouvez les ouvrir avec n’importe quel éditeur de textes.

Voici un exemple extrait du corpus :

\begin{verbatim}
# sent_id= annodis.er_00007
# text= Amélioration de la sécurité
1 Amélioration amélioration NOUN _ Gender=Fem|Number=Sing 0 root _ _ * Act *
2 de de ADP _ _ 4 case _ _ _ * * *
3 la le DET _ Definite=Def|Gender=Fem|Number=Sing|PronType=Art 4 det _ _ * * * 
4 sécurité sécurité NOUN _ Gender=Fem|Number=Sing 1 nmod _ _ * State *
\end{verbatim}

Le corpus est segmenté en phrases, et chaque phrase est segmentée en mots. Chaque ligne du fichier contient un mot, avec des lignes blanches pour séparer les phrases entre elles. Les phrases se lisent donc à la verticale !

Chaque mot contient 13 colonnes séparées par des tabulations (TAB ou \textbackslash t), avec un type d’information linguistique par colonne. Les noms des colonnes sont donnés dans la toute première ligne du fichier. 

Les métainformations (lignes commençant par \texttt{\#}) peuvent être ignorées. L’entrée de votre système sera toujours la \textbf{deuxième colonne} : \texttt{FORM}. Il s’agit du mot tel qu’il apparaît dans le corpus, sans aucune annotation.\footnote{Vous remarquerez que la tokenisation a séparé les contractions, par exemple : \textit{aux} $\rightarrow$ \textit{à les}, \textit{du} $\rightarrow$ \textit{de le}, \textit{duquel} $\rightarrow$ \textit{de lequel}.}

Le système doit prédire les autres colonnes ; par exemple, ce TP permettra de faire un système qui prédit la colonne numéro 4 (\texttt{UPOS}). Vous trouverez la description du format CoNLL-U (10 premières colonnes) sur le site de Universal Dependencies.\footnote{\url{https://universaldependencies.org/format}}

Nous vous conseillons la bibliothèque \texttt{https://pypi.org/project/conllu/}. La fonction \texttt{parse\_incr} est particulièrement utile pour récupérer des \texttt{TokenList}, où chaque élément est un dictionnaire représentant le mot avec ses annotations. Voici un exemple :

\begin{lstlisting}
from conllu import parse_incr

for sent in parse_incr(open("./sequoia/sequoia-ud.parseme.frsemcor.simple.small", encoding='UTF-8')):
    print("".join(tok["upos"] for tok in sent))
\end{lstlisting}

\section{Données et code fournis}

Des données et du code sont fournis dans \texttt{https://gitlab.lis-lab.fr/carlos.ramisch/pstal-etu}. Il s’agit d’un dépôt git qu’il convient d’actualiser souvent (\texttt{git pull}) pour avoir la dernière version des fichiers.

Dans le dossier \texttt{lib/}, vous trouverez le script d’évaluation \texttt{evaluate.py}. Son fonctionnement est expliqué dans \texttt{./evaluate.py --help}. Le module \texttt{conllulib.py} regroupe des fonctions qui peuvent vous être utiles.

Le dossier \texttt{sequoia/} contient 5 fichiers CoNLL-U+ nommés \texttt{sequoia-ud.parseme.frsemcor.simple} :
\begin{itemize}
\item \texttt{.train} : données d’entraînement
    \item \texttt{.dev} : données de validation/développement
    \item \texttt{.test} : données de test
    \item \texttt{.full} : union des trois fichiers précédents : \textbf{ne doit jamais être utilisé tel quel}
    \item \texttt{.small} : extrait du \texttt{.dev}, pratique pour développer et déboguer
\end{itemize}

\textbf{Rappel :} vos expériences doivent être réalisées sur le corpus \texttt{.dev}. Vous ne reporterez les résultats sur le \texttt{.test} qu’à la toute fin.

\section{Préparation des données}

Le modèle requiert des tenseurs en entrée/sortie. Chaque élément du tenseur est un indice représentant un mot/étiquette dans le vocabulaire. Il faut donc convertir les entrées (mots) et sorties (étiquettes) en suites d’entiers, et construire en parallèle le vocabulaire des mots $\mathcal{V}_w$ et des étiquettes $\mathcal{V}_t$.

N’oubliez pas de garder un indice à part pour le \textbf{padding} (par exemple : \texttt{PAD\_ID=0}) dans $\mathcal{V}_w$ et $\mathcal{V}_t$, et un indice pour les OOV dans $\mathcal{V}_w$ (par exemple : \texttt{UNK\_ID=1}).

L’encodage est nécessaire pour \texttt{.train} et pour \texttt{.dev}. Les mots du \texttt{.dev} absents de $\mathcal{V}_w$ sont encodés avec \texttt{UNK\_ID}.

La structure \texttt{defaultdict} est pratique pour encoder les vocabulaires, comme illustré dans \texttt{conllulib}.

Des \textbf{batches} regrouperont des phrases de longueur variable. Il faut donc :
\begin{enumerate}
    \item \textbf{tronquer} les phrases dépassant la longueur maximale $L$ ;
    \item \textbf{ajouter du padding} pour les phrases plus courtes que $L$.
\end{enumerate}

Les phrases tronquées, paddées, et transformées en \texttt{LongTensor} sont transmises à la fonction \texttt{Util.dataloader} dans \texttt{conllulib}.

\section{Le modèle RNN d’étiquetage}

Le modèle d’étiquetage est une classe héritant de \texttt{nn.Module} contenant les éléments suivants :
\begin{itemize}
\item \texttt{nn.Embedding} : matrice de dimensions $|\mathcal{V}_w| \times d_e$, prenant en entrée des entiers représentant les mots, et donnant en sortie un vecteur de dimension $d_e$ par mot. Contrairement à Keras, vous ne transformerez pas les entiers en one-hot — cela est automatique. Le \textit{broadcast} est aussi automatique : si votre entrée est un \texttt{LongTensor} de dimension $B \times L$ (où $B$ est la taille du batch et $L$ la longueur des phrases), la sortie sera de dimension $B \times L \times d_e$, avec un vecteur de dimension $d_e$ par entrée. Il est important d’indiquer l’indice du padding (\texttt{padding\_idx=PAD\_ID}) pour que ce vecteur reste nul pendant l’apprentissage.

    \item \texttt{nn.GRU} : pour chaque embedding de dimension $d_e$, la couche récurrente génère un vecteur caché de dimension $d_h$. Contrairement à Keras, la longueur $L$ de la suite n’est pas un paramètre de la couche : comme le graphe de calcul est dynamique, la couche admet des séquences de longueur variable. Nous devons indiquer à cette couche que \texttt{batch\_first=True}. De plus, nous ne voulons pas de biais (\texttt{bias=False}) car celui-ci interférerait sur le padding dans un réseau bidirectionnel.

    \item \texttt{nn.Linear} : la couche de décision est une matrice de dimension $d_h \times |\mathcal{V}_t|$. L’activation \texttt{softmax} est intégrée dans la loss et n’est pas appelée explicitement. N’oubliez pas d’ajouter un peu de \texttt{dropout}.
\end{itemize}

\section{Entraînement du modèle}

Si dans Keras il suffit d’appeler \texttt{model.fit}, dans PyTorch il faut écrire sa propre fonction \texttt{fit(model, data)}.

Heureusement, elle est similaire d’un projet à l’autre ; on peut copier puis adapter. La fonction \texttt{fit} doit :

\begin{enumerate}
    \item Initialiser la fonction de perte (\texttt{nn.CrossEntropyLoss}) et l’optimiseur (par exemple : \texttt{optim.Adam})
    \item Dans la boucle extérieure, répéter un certain nombre d’epochs
    \item Dans la boucle intérieure, parcourir les \texttt{batches} $(x, y)$ du \texttt{DataLoader} et, pour chaque batch :
    \begin{enumerate}
        \item Mettre à zéro tous les gradients de tous les paramètres du modèle (\texttt{zero\_grad})
        \item Passer $x$ dans le modèle pour obtenir la prédiction $\hat{y}$, puis calculer la \texttt{loss} en fonction de $y$.\footnote{Pensez à transposer les 2 dernières dimensions de $\hat{y}$ pour la rendre compatible avec le format attendu par la loss.}
        \item Rétro-propager les gradients (\texttt{backward}), et mettre les paramètres à jour (\texttt{optimizer.step})
    \end{enumerate}
\end{enumerate}

Ces étapes constituent le cœur de l’apprentissage. Mais pour s’assurer que tout se passe bien, il convient d’afficher, à la fin de chaque epoch :
\begin{itemize}
    \item la \texttt{loss} cumulée sur le \texttt{.train},
    \item la \texttt{loss} et l’accuracy sur le \texttt{.dev}.
\end{itemize}

Écrivez une fonction \texttt{perf} qui parcourt les \texttt{batches} $(x, y)$ du \texttt{DataLoader} \texttt{dev}, prédit les scores des étiquettes $\hat{y}$, accumule les valeurs de la cross-entropie, comme pour l’entraînement, puis les affiche.

L’accuracy (exactitude) sur le \texttt{.dev} peut aussi être calculée dans \texttt{perf}. Pour cela, transformez les logits $\hat{y}$ en indices d’étiquettes prédites $\hat{t}$ (\texttt{argmax} de $\hat{y}$). Mais attention : nous voulons ignorer le padding, il faut donc le masquer. Le code \texttt{mask = (y != PAD\_ID)} permet d’obtenir un tenseur de masquage, appliqué ensuite à la comparaison de $\hat{t}$ avec $y$, par exemple : \texttt{(t\_hat == y) * mask}.

Pensez à mettre le modèle en mode \texttt{model.train} au début des epochs, et de le mettre en mode \texttt{model.eval} lors du calcul des performances sur le \texttt{.dev}.

Une fois le modèle entraîné, il ne faut surtout pas le jeter (comme on fait souvent dans les Jupyter notebooks) ! Sauvegardez le modèle \texttt{model.state\_dict} dans un fichier \texttt{.pt}. Il faut également sauvegarder les vocabulaires $\mathcal{V}_w$ et $\mathcal{V}_t$, sans quoi le modèle sera inutilisable.

Notez que \texttt{torch.save} accepte des dictionnaires quelconques : vous pouvez tout sauvegarder ensemble : les paramètres du modèle et les vocabulaires.\footnote{Avant la sauvegarde, transformez $\mathcal{V}_w$ et $\mathcal{V}_t$ en \texttt{dict} Python standard, sinon vous aurez une erreur.}

Profitez pour sauvegarder aussi les hyperparamètres nécessaires à la prédiction dans ce même fichier ($d_e$, $d_h$, \texttt{PAD\_ID}, etc.).

\section{Prédiction}

L’étiqueteur prend en entrée un corpus \texttt{.dev} et un modèle entraîné. Le modèle est d’abord instancié (Sec. 6), puis initialisé avec \texttt{load\_state\_dict}.\footnote{Spécifiez \texttt{weights\_only=False} pour éviter le warning de sécurité.}

Chaque phrase du \texttt{.dev} doit être transformée en entiers à l’aide de $\mathcal{V}_w$, passée dans le modèle pour obtenir $\hat{y}$, puis $\hat{t}$ (\texttt{argmax} de $\hat{y}$). La fonction \texttt{rev\_vocab} dans \texttt{conllulib} permet de convertir les indices en étiquettes POS, à placer dans le champ \texttt{upos} des mots avant d’imprimer la phrase avec \texttt{serialize}. La prédiction se fait par phrase et non pas par batch : il n’y a donc pas de troncage ni de padding.

\section{Travail à effectuer}
Vous devez écrire deux scripts différents :
\begin{itemize}
\item \texttt{train\_postag.py} pour l’entraînement du modèle (Sec. 7),
    \item \texttt{predict\_postag.py} pour la prédiction des POS (Sec. 8).
\end{itemize}

Le code du modèle RNN (Sec. 6) doit être partagé par les deux scripts : vous pouvez le mettre dans un module/fichier à part et l’importer, par exemple.

L’évaluation des prédictions sera effectuée par le script fourni \texttt{lib/evaluate.py}.

\end{document}